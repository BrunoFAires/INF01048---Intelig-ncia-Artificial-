{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAc0_xPQ6g8e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cifar10_network():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_fashion_mnist_network():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_mnist_network():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_cifar100_network():\n",
        "    model = keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "      tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(100, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "NuPZrY1-6nAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "   Mnist\n",
        "\"\"\"\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images, test_images = train_images/255, test_images/255\n",
        "\n",
        "model = get_mnist_network()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Acur치cia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "7MZnyAcn7Llf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511fce97-b18d-4cb6-b69c-18d2078dab0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Fashion\n",
        "\"\"\"\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_images, test_images = train_images/255, test_images/255\n",
        "\n",
        "\n",
        "model = get_fashion_mnist_network()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Acur치cia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "-1pb9YVe7Tav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Cifar-10\n",
        "\"\"\"\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "train_images, test_images = train_images/255, test_images/255\n",
        "\n",
        "len(train_images)\n",
        "# model = get_cifar10_network()\n",
        "\n",
        "# model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "# test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "# print(f'Acur치cia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "hOOyliUG7Y0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bece09fb-d5b5-424f-d11b-44402346af0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Cifar-100\n",
        "\"\"\"\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "train_images, test_images = train_images/255, test_images/255\n",
        "\n",
        "model = get_cifar100_network()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Acur치cia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "Xt1KI8cu7a9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a80ed9-4f4b-43f5-af2f-f2642314a78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 16)        448       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 128)       73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 15488)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               3965184   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 256)               1024      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               25700     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4156164 (15.85 MB)\n",
            "Trainable params: 4155140 (15.85 MB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 366s 232ms/step - loss: 3.9788 - accuracy: 0.1009\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 362s 232ms/step - loss: 3.3492 - accuracy: 0.1896\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 361s 231ms/step - loss: 2.9459 - accuracy: 0.2659\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 355s 227ms/step - loss: 2.6601 - accuracy: 0.3233\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 344s 220ms/step - loss: 2.4753 - accuracy: 0.3594\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 352s 225ms/step - loss: 2.3218 - accuracy: 0.3938\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 365s 234ms/step - loss: 2.1758 - accuracy: 0.4244\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 363s 233ms/step - loss: 2.0419 - accuracy: 0.4509\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 367s 235ms/step - loss: 1.9047 - accuracy: 0.4803\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 350s 224ms/step - loss: 1.7839 - accuracy: 0.5086\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 2.3126 - accuracy: 0.4147\n",
            "Acur치cia no conjunto de teste: 41.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    \"mnist\": {\"time\": 516, \"acc\": 99.13},\n",
        "    \"fashion_mnist\": {\"time\": 430, \"acc\": 90.89},\n",
        "    \"cifar10\": {\"time\": 350, \"acc\": 63.95},\n",
        "    \"cifar100\": {\"time\": 3585, \"acc\": 41.47},\n",
        "}"
      ],
      "metadata": {
        "id": "XIUpq0kE6wYF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}